# ES搜索引出的logstash优化问题
之前搭建了elk，但在搜索es的时候一旦卡了条件就查不到结果，上网查了下发现是
logstash在往es里写的时候没设置mapping，，mapping会指定存入es里的字段的类型，
在es5.x中，logstash默认写入es中的字段格式如下：
```
{
  "test-logs": {
    "mappings": {
      "logs": {
        "properties": {
          "field_name": {
            "type": "text",
            "fields": {
              "keyword": {
                "type": "keyword",
                "ignore_above": 256
              }
            }
          }
        }
      }
    }
  }
}
```
es5.x引入了**test**和**keyword**两种数据类型用来取代**string**类型，两者区别：
- *test*类型在存储时会自动分词
- *keyword*类型在存储时不会自动分词

这就导致卡条件时test类型没法精确匹配，所以需要在logstash写入es时配置mapping
定义字段格式为keyword。具体配置如下：
- 定义mapping文件（test-logs.json）
```
{
    "template":"test-logs",//需跟logstash配置文件中的index相匹配
    "settings":{
        "index.refresh_interval":"1s"
    },
    "mappings":{
        "logs":{
            "properties":{
                "fieldA":{
                    "type":"date"
                },
                "fieldB":{
                    "type":"keyword"
                },
                "fieldC":{
                    "type":"long"
                }
            }
        }
    }
}
```
- 配置logstash文件（test.conf）
```
//修改输出配置如下
output {
    stdout{codec =>rubydebug}
    elasticsearch {
      hosts => ["http://12.221.21.222:9200"] //安装es集群的地址
      flush_size => 1000 //刷新频率
      index => "test-logs" //es中创建索引的名称
      template => "test-logs.json文件的路径"
      template_name => "test*"
      template_overwrite => true

    }
}
```

这样一来，就可以成功搜索了。
